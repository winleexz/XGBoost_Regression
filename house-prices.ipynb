{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport warnings\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom IPython.display import display\nfrom pandas.api.types import CategoricalDtype\n\nfrom category_encoders import MEstimateEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom xgboost import XGBRegressor\n\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\n\n# Mute warnings\nwarnings.filterwarnings('ignore')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-15T15:46:03.514752Z","iopub.execute_input":"2021-08-15T15:46:03.515426Z","iopub.status.idle":"2021-08-15T15:46:04.149742Z","shell.execute_reply.started":"2021-08-15T15:46:03.515324Z","shell.execute_reply":"2021-08-15T15:46:04.148876Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing ##\n\n- **Load** the data from CSV files\n- **Clean** the data to fix any errors or inconsistencies\n- **Encode** the statistical data type (numeric, categorical)\n- **Impute** any missing values","metadata":{}},{"cell_type":"code","source":"def load_data():\n    # Read data\n    data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n    df_train = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n    df_test = pd.read_csv(data_dir / \"test.csv\", index_col=\"Id\")\n    # Merge the splits so we can process them together\n    df = pd.concat([df_train, df_test])\n    # Preprocessing\n    df = clean(df)\n    df = encode(df)\n    df = impute(df)\n    # Reform splits\n    df_train = df.loc[df_train.index, :]\n    df_test = df.loc[df_test.index, :]\n    return df_train, df_test","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:46:09.137806Z","iopub.execute_input":"2021-08-15T15:46:09.138167Z","iopub.status.idle":"2021-08-15T15:46:09.146520Z","shell.execute_reply.started":"2021-08-15T15:46:09.138135Z","shell.execute_reply":"2021-08-15T15:46:09.144856Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Clean Data ###","metadata":{}},{"cell_type":"code","source":"data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\ndf = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n\ndf.Exterior2nd.unique()","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:46:20.531860Z","iopub.execute_input":"2021-08-15T15:46:20.532211Z","iopub.status.idle":"2021-08-15T15:46:20.573094Z","shell.execute_reply.started":"2021-08-15T15:46:20.532183Z","shell.execute_reply":"2021-08-15T15:46:20.572241Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"array(['VinylSd', 'MetalSd', 'Wd Shng', 'HdBoard', 'Plywood', 'Wd Sdng',\n       'CmentBd', 'BrkFace', 'Stucco', 'AsbShng', 'Brk Cmn', 'ImStucc',\n       'AsphShn', 'Stone', 'Other', 'CBlock'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:46:23.075186Z","iopub.execute_input":"2021-08-15T15:46:23.075646Z","iopub.status.idle":"2021-08-15T15:46:23.081832Z","shell.execute_reply.started":"2021-08-15T15:46:23.075611Z","shell.execute_reply":"2021-08-15T15:46:23.080847Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(1460, 80)"},"metadata":{}}]},{"cell_type":"code","source":"df.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:46:25.865588Z","iopub.execute_input":"2021-08-15T15:46:25.866112Z","iopub.status.idle":"2021-08-15T15:46:25.898789Z","shell.execute_reply.started":"2021-08-15T15:46:25.866081Z","shell.execute_reply":"2021-08-15T15:46:25.897551Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\nId                                                                    \n1           60       RL         65.0     8450   Pave   NaN      Reg   \n2           20       RL         80.0     9600   Pave   NaN      Reg   \n3           60       RL         68.0    11250   Pave   NaN      IR1   \n\n   LandContour Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature  \\\nId                                  ...                                     \n1          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n2          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n3          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n\n   MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \nId                                                             \n1        0      2    2008        WD         Normal     208500  \n2        0      5    2007        WD         Normal     181500  \n3        0      9    2008        WD         Normal     223500  \n\n[3 rows x 80 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>LotConfig</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>FR2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 80 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Comparing these to `data_description.txt` shows us what needs cleaning e.g. typo erros.","metadata":{}},{"cell_type":"code","source":"def clean(df):\n    df[\"Exterior2nd\"] = df[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n    # Some values of GarageYrBlt are corrupt, so we'll replace them\n    # with the year the house was built\n    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].where(df.GarageYrBlt <= 2010, df.YearBuilt)\n    # Names beginning with numbers are awkward to work with\n    df.rename(columns={\n        \"1stFlrSF\": \"FirstFlrSF\",\n        \"2ndFlrSF\": \"SecondFlrSF\",\n        \"3SsnPorch\": \"Threeseasonporch\",\n    }, inplace=True,\n    )\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:46:29.171474Z","iopub.execute_input":"2021-08-15T15:46:29.171822Z","iopub.status.idle":"2021-08-15T15:46:29.178849Z","shell.execute_reply.started":"2021-08-15T15:46:29.171793Z","shell.execute_reply":"2021-08-15T15:46:29.177478Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Encode the Statistical Data Type ###","metadata":{}},{"cell_type":"code","source":"# The numeric features are already encoded correctly (`float` for\n# continuous, `int` for discrete), but the categoricals we'll need to\n# do ourselves. Note in particular, that the `MSSubClass` feature is\n# read as an `int` type, but is actually a (nominative) categorical.\n\n# The nominative (unordered) categorical features\nfeatures_nom = [\"MSSubClass\", \"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \"LotConfig\", \n                \"Neighborhood\", \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \n                \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \n                \"Foundation\", \"Heating\", \"CentralAir\", \"GarageType\", \"MiscFeature\", \n                \"SaleType\", \"SaleCondition\"]\n\n\n# The ordinal (ordered) categorical features \n\n# Pandas calls the categories \"levels\"\nfive_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\nten_levels = list(range(10))\n\nordered_levels = {\n    \"OverallQual\": ten_levels,\n    \"OverallCond\": ten_levels,\n    \"ExterQual\": five_levels,\n    \"ExterCond\": five_levels,\n    \"BsmtQual\": five_levels,\n    \"BsmtCond\": five_levels,\n    \"HeatingQC\": five_levels,\n    \"KitchenQual\": five_levels,\n    \"FireplaceQu\": five_levels,\n    \"GarageQual\": five_levels,\n    \"GarageCond\": five_levels,\n    \"PoolQC\": five_levels,\n    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n    \"CentralAir\": [\"N\", \"Y\"],\n    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n    \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n}\n\n# Add a None level for missing values\nordered_levels = {key: [\"None\"] + value for key, value in\n                  ordered_levels.items()}\n\n\ndef encode(df):\n    # Nominal categories\n    for name in features_nom:\n        df[name] = df[name].astype(\"category\")\n        # Add a None category for missing values\n        if \"None\" not in df[name].cat.categories:\n            df[name].cat.add_categories(\"None\", inplace=True)\n    # Ordinal categories\n    for name, levels in ordered_levels.items():\n        df[name] = df[name].astype(CategoricalDtype(levels,\n                                                    ordered=True))\n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-15T15:47:21.534525Z","iopub.execute_input":"2021-08-15T15:47:21.535144Z","iopub.status.idle":"2021-08-15T15:47:21.549765Z","shell.execute_reply.started":"2021-08-15T15:47:21.535110Z","shell.execute_reply":"2021-08-15T15:47:21.548949Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Handle Missing Values ###","metadata":{}},{"cell_type":"code","source":"# Impute `0` for missing numeric values and `\"None\"` for missing categorical values\n\ndef impute(df):\n    for name in df.select_dtypes(\"number\"):\n        df[name] = df[name].fillna(0)\n    for name in df.select_dtypes(\"category\"):\n        df[name] = df[name].fillna(\"None\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:48:35.233616Z","iopub.execute_input":"2021-08-15T15:48:35.234025Z","iopub.status.idle":"2021-08-15T15:48:35.239669Z","shell.execute_reply.started":"2021-08-15T15:48:35.233982Z","shell.execute_reply":"2021-08-15T15:48:35.238630Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Load Data ##\n\nAnd now we can call the data loader and get the processed data splits:","metadata":{}},{"cell_type":"code","source":"df_train, df_test = load_data()","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:49:45.725588Z","iopub.execute_input":"2021-08-15T15:49:45.726032Z","iopub.status.idle":"2021-08-15T15:49:45.968580Z","shell.execute_reply.started":"2021-08-15T15:49:45.725999Z","shell.execute_reply":"2021-08-15T15:49:45.967507Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Establish Baseline using XGBoost Model ##","metadata":{}},{"cell_type":"code","source":"def score_dataset(X, y, model=XGBRegressor()):\n    for colname in X.select_dtypes([\"category\"]):\n        X[colname] = X[colname].cat.codes\n    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n    log_y = np.log(y)\n    score = cross_val_score(\n        model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\",\n    )\n    score = -1 * score.mean()\n    score = np.sqrt(score)\n    return score","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-15T15:53:07.819927Z","iopub.execute_input":"2021-08-15T15:53:07.820295Z","iopub.status.idle":"2021-08-15T15:53:07.826618Z","shell.execute_reply.started":"2021-08-15T15:53:07.820247Z","shell.execute_reply":"2021-08-15T15:53:07.825587Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop(\"SalePrice\")\n\nbaseline_score = score_dataset(X, y)\nprint(f\"Baseline score: {baseline_score:.5f} RMSLE\")","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:53:18.508699Z","iopub.execute_input":"2021-08-15T15:53:18.509234Z","iopub.status.idle":"2021-08-15T15:53:20.424436Z","shell.execute_reply.started":"2021-08-15T15:53:18.509204Z","shell.execute_reply":"2021-08-15T15:53:20.423631Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Baseline score: 0.14351 RMSLE\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Step 2 - Feature Utility Scores using Mutual Information #","metadata":{}},{"cell_type":"code","source":"def make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-15T15:53:36.448423Z","iopub.execute_input":"2021-08-15T15:53:36.448827Z","iopub.status.idle":"2021-08-15T15:53:36.458724Z","shell.execute_reply.started":"2021-08-15T15:53:36.448793Z","shell.execute_reply":"2021-08-15T15:53:36.457353Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"Let's look at our feature scores again:","metadata":{}},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop(\"SalePrice\")\n\nmi_scores = make_mi_scores(X, y)\nmi_scores","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:53:41.680532Z","iopub.execute_input":"2021-08-15T15:53:41.680942Z","iopub.status.idle":"2021-08-15T15:53:44.114064Z","shell.execute_reply.started":"2021-08-15T15:53:41.680909Z","shell.execute_reply":"2021-08-15T15:53:44.112996Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"OverallQual     0.571457\nNeighborhood    0.526220\nGrLivArea       0.430395\nYearBuilt       0.407974\nLotArea         0.394468\n                  ...   \nPoolQC          0.000000\nMiscFeature     0.000000\nMiscVal         0.000000\nMoSold          0.000000\nYrSold          0.000000\nName: MI Scores, Length: 79, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# drop uninformative features\n\ndef drop_uninformative(df, mi_scores):\n    return df.loc[:, mi_scores > 0.0]","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:54:02.882574Z","iopub.execute_input":"2021-08-15T15:54:02.882945Z","iopub.status.idle":"2021-08-15T15:54:02.888483Z","shell.execute_reply.started":"2021-08-15T15:54:02.882913Z","shell.execute_reply":"2021-08-15T15:54:02.887238Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop(\"SalePrice\")\nX = drop_uninformative(X, mi_scores)\n\nscore_dataset(X, y) # removing uninformative features improve the score","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:54:08.084942Z","iopub.execute_input":"2021-08-15T15:54:08.085338Z","iopub.status.idle":"2021-08-15T15:54:09.916787Z","shell.execute_reply.started":"2021-08-15T15:54:08.085299Z","shell.execute_reply":"2021-08-15T15:54:09.915678Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0.14338026718687277"},"metadata":{}}]},{"cell_type":"markdown","source":"# Step 3 - Create Features #","metadata":{}},{"cell_type":"code","source":"def label_encode(df):\n    X = df.copy()\n    for colname in X.select_dtypes([\"category\"]):\n        X[colname] = X[colname].cat.codes\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:56:01.053779Z","iopub.execute_input":"2021-08-15T15:56:01.054142Z","iopub.status.idle":"2021-08-15T15:56:01.059623Z","shell.execute_reply.started":"2021-08-15T15:56:01.054114Z","shell.execute_reply":"2021-08-15T15:56:01.058587Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def mathematical_transforms(df):\n    X = pd.DataFrame()  # dataframe to hold new features\n    X[\"LivLotRatio\"] = df.GrLivArea / df.LotArea\n    X[\"Spaciousness\"] = (df.FirstFlrSF + df.SecondFlrSF) / df.TotRmsAbvGrd\n    return X\n\n\ndef interactions(df):\n    X = pd.get_dummies(df.BldgType, prefix=\"Bldg\")\n    X = X.mul(df.GrLivArea, axis=0)\n    return X\n\n\ndef counts(df):\n    X = pd.DataFrame()\n    X[\"PorchTypes\"] = df[[\n        \"WoodDeckSF\",\n        \"OpenPorchSF\",\n        \"EnclosedPorch\",\n        \"Threeseasonporch\",\n        \"ScreenPorch\",\n    ]].gt(0.0).sum(axis=1)\n    return X\n\n\ndef break_down(df):\n    X = pd.DataFrame()\n    X[\"MSClass\"] = df.MSSubClass.str.split(\"_\", n=1, expand=True)[0]\n    return X\n\n\ndef group_transforms(df):\n    X = pd.DataFrame()\n    X[\"MedNhbdArea\"] = df.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n    return X","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-15T15:56:31.420744Z","iopub.execute_input":"2021-08-15T15:56:31.421095Z","iopub.status.idle":"2021-08-15T15:56:31.432521Z","shell.execute_reply.started":"2021-08-15T15:56:31.421065Z","shell.execute_reply":"2021-08-15T15:56:31.431471Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Principal Component Analysis to Create Additional Features ##","metadata":{}},{"cell_type":"code","source":"def apply_pca(X, standardize=True):\n    # Standardize\n    if standardize:\n        X = (X - X.mean(axis=0)) / X.std(axis=0)\n    # Create principal components\n    pca = PCA()\n    X_pca = pca.fit_transform(X)\n    # Convert to dataframe\n    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n    X_pca = pd.DataFrame(X_pca, columns=component_names)\n    # Create loadings\n    loadings = pd.DataFrame(\n        pca.components_.T,  # transpose the matrix of loadings\n        columns=component_names,  # so the columns are the principal components\n        index=X.columns,  # and the rows are the original features\n    )\n    return pca, X_pca, loadings\n\n\ndef plot_variance(pca, width=8, dpi=100):\n    # Create figure\n    fig, axs = plt.subplots(1, 2)\n    n = pca.n_components_\n    grid = np.arange(1, n + 1)\n    # Explained variance\n    evr = pca.explained_variance_ratio_\n    axs[0].bar(grid, evr)\n    axs[0].set(\n        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n    )\n    # Cumulative Variance\n    cv = np.cumsum(evr)\n    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n    axs[1].set(\n        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n    )\n    # Set up figure\n    fig.set(figwidth=8, dpi=100)\n    return axs","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-15T15:56:56.301186Z","iopub.execute_input":"2021-08-15T15:56:56.301728Z","iopub.status.idle":"2021-08-15T15:56:56.312412Z","shell.execute_reply.started":"2021-08-15T15:56:56.301696Z","shell.execute_reply":"2021-08-15T15:56:56.311617Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def pca_inspired(df):\n    X = pd.DataFrame()\n    X[\"Feature1\"] = df.GrLivArea + df.TotalBsmtSF\n    X[\"Feature2\"] = df.YearRemodAdd * df.TotalBsmtSF\n    return X\n\n\ndef pca_components(df, features):\n    X = df.loc[:, features]\n    _, X_pca, _ = apply_pca(X)\n    return X_pca\n\n\npca_features = [\n    \"GarageArea\",\n    \"YearRemodAdd\",\n    \"TotalBsmtSF\",\n    \"GrLivArea\",\n]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-15T15:57:04.262035Z","iopub.execute_input":"2021-08-15T15:57:04.262529Z","iopub.status.idle":"2021-08-15T15:57:04.268923Z","shell.execute_reply.started":"2021-08-15T15:57:04.262498Z","shell.execute_reply":"2021-08-15T15:57:04.267980Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## Target Encoding on Multiple Splits of Dataset ##","metadata":{}},{"cell_type":"code","source":"class CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=5)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-15T15:58:24.058779Z","iopub.execute_input":"2021-08-15T15:58:24.059137Z","iopub.status.idle":"2021-08-15T15:58:24.070969Z","shell.execute_reply.started":"2021-08-15T15:58:24.059108Z","shell.execute_reply":"2021-08-15T15:58:24.069794Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## Create Final Feature Set after Iterations ##","metadata":{}},{"cell_type":"code","source":"def create_features(df, df_test=None):\n    X = df.copy()\n    y = X.pop(\"SalePrice\")\n    mi_scores = make_mi_scores(X, y)\n\n    # Combine splits if test data is given\n    #\n    # If we're creating features for test set predictions, we should\n    # use all the data we have available. After creating our features,\n    # we'll recreate the splits.\n    if df_test is not None:\n        X_test = df_test.copy()\n        X_test.pop(\"SalePrice\")\n        X = pd.concat([X, X_test])\n\n    # Mutual Information\n    X = drop_uninformative(X, mi_scores)\n\n    # Transformations\n    X = X.join(mathematical_transforms(X))\n    X = X.join(interactions(X))\n    X = X.join(counts(X))\n    X = X.join(group_transforms(X))\n\n    # PCA\n    X = X.join(pca_inspired(X))\n    X = label_encode(X)\n\n    # Reform splits\n    if df_test is not None:\n        X_test = X.loc[df_test.index, :]\n        X.drop(df_test.index, inplace=True)\n\n    # Target Encoder\n    encoder = CrossFoldEncoder(MEstimateEncoder, m=1)\n    X = X.join(encoder.fit_transform(X, y, cols=[\"MSSubClass\"]))\n    if df_test is not None:\n        X_test = X_test.join(encoder.transform(X_test))\n\n    if df_test is not None:\n        return X, X_test\n    else:\n        return X\n\n\ndf_train, df_test = load_data()\nX_train = create_features(df_train)\ny_train = df_train.loc[:, \"SalePrice\"]\n\nscore_dataset(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:58:44.144824Z","iopub.execute_input":"2021-08-15T15:58:44.145232Z","iopub.status.idle":"2021-08-15T15:58:49.217837Z","shell.execute_reply.started":"2021-08-15T15:58:44.145198Z","shell.execute_reply":"2021-08-15T15:58:49.216993Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"0.1381925629969659"},"metadata":{}}]},{"cell_type":"markdown","source":"# Step 4 - Hyperparameter Tuning #\n\nAt this stage, you might like to do some hyperparameter tuning with XGBoost before creating your final submission.","metadata":{}},{"cell_type":"code","source":"X_train = create_features(df_train)\ny_train = df_train.loc[:, \"SalePrice\"]\n\nxgb_params = dict(\n    max_depth=6,           # maximum depth of each tree - try 2 to 10\n    learning_rate=0.01,    # effect of each tree - try 0.0001 to 0.1\n    n_estimators=1000,     # number of trees (that is, boosting rounds) - try 1000 to 8000\n    min_child_weight=1,    # minimum number of houses in a leaf - try 1 to 10\n    colsample_bytree=0.7,  # fraction of features (columns) per tree - try 0.2 to 1.0\n    subsample=0.7,         # fraction of instances (rows) per tree - try 0.2 to 1.0\n    reg_alpha=0.5,         # L1 regularization (like LASSO) - try 0.0 to 10.0\n    reg_lambda=1.0,        # L2 regularization (like Ridge) - try 0.0 to 10.0\n    num_parallel_tree=1,   # set > 1 for boosted random forests\n)\n\nxgb = XGBRegressor(**xgb_params)\nscore_dataset(X_train, y_train, xgb)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T15:59:34.290149Z","iopub.execute_input":"2021-08-15T15:59:34.290576Z","iopub.status.idle":"2021-08-15T15:59:52.069472Z","shell.execute_reply.started":"2021-08-15T15:59:34.290535Z","shell.execute_reply":"2021-08-15T15:59:52.068253Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"0.12414985267470383"},"metadata":{}}]},{"cell_type":"markdown","source":"# Step 5 - Train Model #","metadata":{}},{"cell_type":"code","source":"X_train, X_test = create_features(df_train, df_test)\ny_train = df_train.loc[:, \"SalePrice\"]\n\nxgb = XGBRegressor(**xgb_params)\n# XGB minimizes MSE, but competition loss is RMSLE\n# So, we need to log-transform y to train and exp-transform the predictions\nxgb.fit(X_train, np.log(y))\npredictions = np.exp(xgb.predict(X_test))\n\noutput = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\noutput.to_csv('my_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T16:20:50.687016Z","iopub.execute_input":"2021-08-15T16:20:50.687420Z","iopub.status.idle":"2021-08-15T16:20:56.753559Z","shell.execute_reply.started":"2021-08-15T16:20:50.687374Z","shell.execute_reply":"2021-08-15T16:20:56.752602Z"},"trusted":true},"execution_count":49,"outputs":[]}]}